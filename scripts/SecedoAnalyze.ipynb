{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-training",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T14:22:31.802606Z",
     "start_time": "2021-08-18T14:22:31.771778Z"
    }
   },
   "outputs": [],
   "source": [
    "cov = 1  # 1 means simple (0.03x), 2 means double (0.06x), etc.\n",
    "slice='ABCDE'\n",
    "\n",
    "base_dir = f'/Users/dd/work/svc/data/secedo_{slice}_5_05'\n",
    "\n",
    "clusters = open(f'{base_dir}/spectral_clusteringCAA').readlines()[0][:-1].split(',')\n",
    "chisel_clustering_lines = open(f'{base_dir}/../mapping_all.tsv').readlines()\n",
    "\n",
    "# contains <cell_id, ground_truth, cluster>, where \"ground truth\" is the result of CNV analysis\n",
    "result = open(f'{base_dir}/../cell_id_gt_spectral', 'w')\n",
    "\n",
    "# the barcode_to_idx file is created by Secedo during pileup construction (it's in pileups/chromosome_{x}.map)\n",
    "# it associates each cell id (barcode) with a zero-based index. This index can be used to associate the Secedo\n",
    "# clustering with the actual cell id/barcode.\n",
    "cell_id_to_idx_lines = open(f'{base_dir}/../barcode_to_idx_{slice}.map').readlines()\n",
    "\n",
    "print(\n",
    "    f'{len(clusters)} clustered cells, {len(cell_id_to_idx_lines)} barcode->id mappings, {len(chisel_clustering_lines)} ground truth (Chisel) entries')\n",
    "\n",
    "cell_id_to_idx = {}\n",
    "cell_idx_to_id = {}\n",
    "for line in cell_id_to_idx_lines:\n",
    "    cell_id, cell_idx = line.split('\\t')\n",
    "    cell_idx = int(cell_idx[:-1])\n",
    "    cell_id_to_idx[cell_id] = cell_idx\n",
    "    cell_idx_to_id[cell_idx] = cell_id\n",
    "\n",
    "cell_id_to_clone_idx = {}\n",
    "for gt_line in chisel_clustering_lines:\n",
    "    gt_line = gt_line.split('\\t')\n",
    "    # cell id is of form A-AAATGCCCATCTGTAG\n",
    "    cell_id_str = gt_line[0]\n",
    "    clone_idx = gt_line[2][:-1]\n",
    "    cell_id_to_clone_idx[cell_id_str] = clone_idx\n",
    "print(cell_id_to_clone_idx)\n",
    "\n",
    "# Assuming a maximum of 3 clusters detected in one Secedo step\n",
    "# The maps below count how many times a cell in a Chisel clone has been assigned by to clusters a/b or c by Secedo\n",
    "# Ideally, all cells in a Chisel clone are assigned to the same cluster by Secedo\n",
    "id_to_cluster_a = {}\n",
    "id_to_cluster_b = {}\n",
    "id_to_cluster_c = {}\n",
    "\n",
    "other_clusters=0\n",
    "for i in range(0, len(clusters)):\n",
    "    cell_id_str = cell_idx_to_id[i]\n",
    "    if cell_id_str not in cell_id_to_clone_idx:\n",
    "        print(f'Could not find clone assignment for cell {cell_id_str}')\n",
    "    clone_idx = cell_id_to_clone_idx[cell_id_str]\n",
    "\n",
    "    result.write(cell_id_str + '\\t' + clone_idx + '\\t' + clusters[i] + '\\n')\n",
    "\n",
    "    if int(clusters[i]) == 0:\n",
    "        if clone_idx not in id_to_cluster_a:\n",
    "            id_to_cluster_a[clone_idx] = 1\n",
    "        else:\n",
    "            id_to_cluster_a[clone_idx] += 1\n",
    "    elif int(clusters[i]) == 1:\n",
    "        if clone_idx not in id_to_cluster_b:\n",
    "            id_to_cluster_b[clone_idx] = 1\n",
    "        else:\n",
    "            id_to_cluster_b[clone_idx] += 1\n",
    "    elif int(clusters[i]) == 2:\n",
    "        if clone_idx not in id_to_cluster_c:\n",
    "            id_to_cluster_c[clone_idx] = 1\n",
    "        else:\n",
    "            id_to_cluster_c[clone_idx] += 1\n",
    "    else:\n",
    "        other_clusters+=1\n",
    "\n",
    "print(\"Other clusters: \", other_clusters)\n",
    "\n",
    "for id, count_a in id_to_cluster_a.items():\n",
    "    count_b = 0\n",
    "    count_c = 0\n",
    "    if id in id_to_cluster_b:\n",
    "        count_b = id_to_cluster_b[id]\n",
    "        del id_to_cluster_b[id]\n",
    "    if id in id_to_cluster_c:\n",
    "        count_c = id_to_cluster_c[id]\n",
    "        del id_to_cluster_c[id]\n",
    "    if count_c > 0:\n",
    "        print(f'{id}: {count_a}/{count_b}/{count_c}')\n",
    "    else:\n",
    "        print(f'{id}: {count_a}/{count_b}')\n",
    "\n",
    "print('==============')\n",
    "\n",
    "for id, count_b in id_to_cluster_b.items():\n",
    "    print(f'{id}: 0/{count_b}')\n",
    "\n",
    "print('==============')\n",
    "\n",
    "for id, count_c in id_to_cluster_c.items():\n",
    "    print(f'{id}: 0/{count_c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate a mapping that groups multiple cells together based on the \"ground truth\" provided by Chisel (CNV-based\n",
    "# clustering)\n",
    "\n",
    "# how many cells of the same type to merge together\n",
    "merge_count = 2\n",
    "\n",
    "chisel_clustering_lines = open('/Users/dd/work/svc/data/mapping_all.tsv').readlines()\n",
    "\n",
    "cell_id_to_group = {}\n",
    "clone_idx_to_count = {}\n",
    "group_count = 0\n",
    "\n",
    "\n",
    "for cell_id, clone_idx in cell_id_to_clone_idx.items():\n",
    "    if cell_id not in cell_id_to_idx:\n",
    "        continue\n",
    "\n",
    "    if clone_idx not in clone_idx_to_count:\n",
    "        clone_idx_to_count[clone_idx] = []\n",
    "\n",
    "    clone_idx_to_count[clone_idx].append(cell_id)\n",
    "\n",
    "\n",
    "    if len(clone_idx_to_count[clone_idx]) == merge_count:\n",
    "        for cell_id in clone_idx_to_count[clone_idx]:\n",
    "            cell_id_to_group[cell_id] = group_count\n",
    "        group_count += 1\n",
    "\n",
    "        del clone_idx_to_count[clone_idx]\n",
    "\n",
    "\n",
    "print(f'Creating {group_count} complete groups and {len(clone_idx_to_count)} incomplete groups')\n",
    "\n",
    "print('Incomplete groups: ', clone_idx_to_count.values())\n",
    "\n",
    "# add incomplete groups\n",
    "for cells in clone_idx_to_count.values():\n",
    "    for cell_id in cells:\n",
    "        cell_id_to_group[cell_id] = group_count\n",
    "    group_count += 1\n",
    "\n",
    "\n",
    "\n",
    "print(f'Group count is {group_count}')\n",
    "\n",
    "group_file = open('/Users/dd/work/svc/data/breast_group_' + str(merge_count), 'w')\n",
    "if group_count > 0:\n",
    "    for i in range(0, len(cell_id_to_group.keys()) - 1):\n",
    "        group_file.write(str(cell_id_to_group[cell_idx_to_id[i]]) + ',')\n",
    "    group_file.write(str(cell_id_to_group[cell_idx_to_id[len(cell_id_to_group.keys()) - 1]]))\n",
    "\n",
    "group_file.close()\n",
    "print('Done!')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute ARI score of Secedo's clustering relative to the Chisel clustering\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "\n",
    "# Parse the SBM Clone output (run via 'python ~/work/sbmclone/sbmclone.py sbm_input'), assign the clusters\n",
    "# to cells and compare to the Chisel ground truth clustering (via the ARI score)\n",
    "\n",
    "print('Mapping back Secedo output to cell ids and comparing with Chisel ground truth')\n",
    "print(f'Secedo clustered {len(clusters)} cell groups')\n",
    "print(f'Expanding group clustering to {len(cell_id_to_idx)} cells...')\n",
    "\n",
    "secedo_cell_clusters = [None] * len(cell_id_to_idx)\n",
    "print(cell_id_to_group)\n",
    "for cell_id, cell_idx in cell_id_to_idx.items():\n",
    "    secedo_cell_clusters[cell_idx] = clusters[cell_id_to_group[cell_idx_to_id[cell_idx]]]\n",
    "\n",
    "open(f'/Users/dd/work/svc/data/output/cluster-assignments-per-cell_9x.txt', 'w').write(','.join(secedo_cell_clusters))\n",
    "\n",
    "print('Evaluating SBMClone performance...')\n",
    "chisel_clusters = []\n",
    "for i, cluster in enumerate(secedo_cell_clusters):\n",
    "    cell_id = cell_idx_to_id[i]\n",
    "    chisel_clusters.append(cell_id_to_clone_idx[cell_id])\n",
    "print(f'ARI Score {ari(secedo_cell_clusters, chisel_clusters)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-kinase",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T14:19:22.877692Z",
     "start_time": "2021-08-18T14:19:22.801958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add ploidy information (from Chisel) to each cell to see if it helps the clustering (it doesn't).\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cov = 1  # 1 means simple (0.03x), 2 means double (0.06x), etc.\n",
    "\n",
    "base_dir = f'/Users/dd/work/svc/data/secedo_{slice}_5_05'\n",
    "\n",
    "\n",
    "fploidy = open(f'{base_dir}/../ploidy_all').readlines()\n",
    "ploidy_map = {}\n",
    "for p in fploidy:\n",
    "    cell_id, ploidy = p[:-1].split(',')\n",
    "    cell_id = cell_id.split('-')[0]\n",
    "    ploidy_map[cell_id] = float(ploidy)\n",
    "\n",
    "eigenvectors = np.loadtxt(f'{base_dir}/sim_mat_eigenvectors_norm.csv')\n",
    "\n",
    "#id_to_group = open(f'{base_dir}/../breast_group_{cov}').readlines()[0].split(',')\n",
    "\n",
    "# different from clustering_info above: it only contains the cells that were actually processed, together\n",
    "# with the gt clustering *and* our clustering\n",
    "clustering_info = open(f'{base_dir}/../cell_id_gt_spectral').readlines()\n",
    "\n",
    "print(f'Gt lines {len(clustering_info)}')\n",
    "\n",
    "# for each type of cell (e.g. Clone159, Clone19), contains the (x,y) coordinates given by the 2nd and 3rd eigenvectors\n",
    "# this allows us to visualize if the clusters are separable in 2D\n",
    "cell_name_to_xy = {}\n",
    "\n",
    "x = eigenvectors[:, 1]\n",
    "y = eigenvectors[:, 2]\n",
    "num_cells = x.shape[0]\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "x2 = []\n",
    "y2 = []\n",
    "p1 = []\n",
    "p2 = []\n",
    "\n",
    "print('Eigenvectors size: ', x.shape[0], '. Cells to process: ', len(clustering_info))\n",
    "\n",
    "j = 0\n",
    "for i in range(0, len(clustering_info)):\n",
    "    gt_str = clustering_info[i].split('\\t')\n",
    "    cell_barcode = gt_str[0]\n",
    "    cluster_name = gt_str[1]\n",
    "    cluster = int(gt_str[2])\n",
    "\n",
    "    if cluster == 16383:  # cell doesn't belong to current subcluster\n",
    "        continue\n",
    "\n",
    "    idx = i # int(id_to_group[i])\n",
    "\n",
    "    if idx >= num_cells:  # shouldn't happen?\n",
    "        j += 1\n",
    "        continue\n",
    "\n",
    "    if cluster_name not in cell_name_to_xy:\n",
    "        cell_name_to_xy[cluster_name] = ([x[idx]], [y[idx]], [ploidy_map[cell_barcode]])\n",
    "    else:\n",
    "        cell_name_to_xy[cluster_name][0].append(x[idx])\n",
    "        cell_name_to_xy[cluster_name][1].append(y[idx])\n",
    "        cell_name_to_xy[cluster_name][2].append(ploidy_map[cell_barcode])\n",
    "\n",
    "    if cluster == 0:\n",
    "        x1.append(x[idx])\n",
    "        y1.append(y[idx])\n",
    "        p1.append(ploidy_map[cell_barcode])\n",
    "    else:\n",
    "        x2.append(x[idx])\n",
    "        y2.append(y[idx])\n",
    "        p2.append(ploidy_map[cell_barcode])\n",
    "\n",
    "print('Skipped ', j, ' records.')\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].scatter(x1, y1, label='tumor', color='red')\n",
    "axs[0].scatter(x2, y2, label='healthy', color='blue')\n",
    "axs[0].set(xlabel='2nd eigenvector', ylabel='3rd eigenvector')\n",
    "\n",
    "# fig, axs = plt.subplots(1)\n",
    "\n",
    "axs[1].scatter(x2, y2, label='healthy', color='blue')\n",
    "axs[1].scatter(x1, y1, label='tumor', color='red')\n",
    "axs[1].set(xlabel='2nd eigenvector', ylabel='3rd eigenvector')\n",
    "\n",
    "fig, axs = plt.subplots(1,  figsize=(15,5))\n",
    "\n",
    "for k, (v1, v2, v3) in cell_name_to_xy.items():\n",
    "    if k=='None':\n",
    "        axs.scatter(v1, v2, label=k, alpha=0.1)\n",
    "    else:\n",
    "        axs.scatter(v1, v2, label=k)\n",
    "\n",
    "# This plots the \"None\" cells at the end\n",
    "# (v1,v2) = cell_name_to_xy['None']\n",
    "# axs.scatter(v1, v2, label='None')\n",
    "\n",
    "axs.set(xlabel='2nd eigenvector', ylabel='3rd eigenvector')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "axs.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-locator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T09:17:49.347481Z",
     "start_time": "2021-11-08T09:17:49.050863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot eigenvectors for the Varsim simulated dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "base_dir = f'/Users/dd/work/svc/data/secedo_ABCDE_5_05'\n",
    "data = np.loadtxt(f'{base_dir}/sim_mat_eigenvectors_normCAA.csv')\n",
    "colors = sns.color_palette('bright')\n",
    "\n",
    "x1 = data[:1000,1]\n",
    "y1 = data[:1000,2]\n",
    "\n",
    "x2 = data[1000:,1]\n",
    "y2 = data[1000:,2]\n",
    "\n",
    "\n",
    "\n",
    "print(data.shape)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(15,5))\n",
    "\n",
    "axs.scatter(x1,y1, label='healthy', color = colors[0])\n",
    "axs.scatter(x2,y2, label='tumor', color = colors[1])\n",
    "\n",
    "\n",
    "\n",
    "axs.set(xlabel='2nd eigenvector', ylabel='3rd eigenvector')\n",
    "\n",
    "#fig, axs = plt.subplots(1)\n",
    "axs.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-philadelphia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T11:58:14.281926Z",
     "start_time": "2021-07-05T11:58:14.268379Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Write out the BAM files that make up each cluster\n",
    "\n",
    "slice='B'\n",
    "\n",
    "base_dir = f'/Users/dd/work/svc/data/silver_{slice}_5_05'\n",
    "clusters = open(f'{base_dir}/clustering').readlines()[0][:-1].split(',')\n",
    "clusters = [int(c) for c in clusters]\n",
    "\n",
    "cell_id_to_idx_lines = open(f'{base_dir}/../cell_id_to_idx_{slice}.map').readlines()\n",
    "\n",
    "\n",
    "cluster_count = int(max(clusters)) + 1\n",
    "\n",
    "print(f'Found {cluster_count} clusters in clustering of size {len(clusters)}')\n",
    "print(f'Found {len(cell_id_to_idx_lines)} cells')\n",
    "\n",
    "print('Creating a list of BAM files for each cluster...')\n",
    "\n",
    "\n",
    "files = [i for i in range(0, cluster_count)]\n",
    "files = [open(base_dir+'/cluster_' + str(i) + '.file_list', 'w') for i in range(0,cluster_count)]\n",
    "\n",
    "for i in range(0, len(clusters)):\n",
    "    fname = cell_id_to_idx_lines[i].split('\\t')[0] + '-1.bam'\n",
    "    files[clusters[i]].write(fname + '\\n')\n",
    "    \n",
    "for f in files:\n",
    "    f.close()\n",
    "\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}